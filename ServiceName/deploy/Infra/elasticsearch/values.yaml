# Permit co-located instances for solitary minikube virtual machines.
#helm install --name elk -f values.yaml stable/elasticsearch --namespace logging
# Default values for elk.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
#helm upgrade -i elasticsearch stable/elastic-stack --namespace elasticsearch -f values.yaml

elasticsearch:
  enabled: true
  client:
    replicas: 1
    additionalJavaOpts: "-XX:MaxRAM=256m -Xms256m -Xmx256m"
  master:
    replicas: 1
    additionalJavaOpts: "-XX:MaxRAM=256m -Xms256m -Xmx256m"
    podDisruptionBudget:
      minAvailable: 1
    persistence:
      enabled: false
  data:    
    replicas: 1
    additionalJavaOpts: "-XX:MaxRAM=256m -Xms256m -Xmx256m"
    persistence:
      enabled: false  
  cluster:
    additionalJavaOpts: "-XX:MaxRAM=256m -Xms256m -Xmx256m"
    env: 
      MINIMUM_MASTER_NODES: "1"
      RECOVER_AFTER_MASTER_NODES: "1"
      EXPECTED_MASTER_NODES: "1"
      ES_JAVA_OPTS: "-XX:MaxRAM=256m -Xms256m -Xmx256m"
    volumeClaimTemplate:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "hostpath"
      resources:
        requests:
          storage: 100M  
kibana:
  enabled: true
  env:
    ELASTICSEARCH_HOSTS: http://elasticsearch-client.{{ .Release.Name }}:9200
    # ELASTICSEARCH_HOSTS: http://elasticsearch-client.{{ .Release.Name }}:9200

logstash:
  enabled: true
  elasticsearch:
    host: elasticsearch-client.elasticsearch.svc.cluster.local
    port: 9200
  logstashJavaOpts: "-XX:MaxRAM=256m -Xms256m -Xmx256m"
filebeat:
  image:
    tag: 7.3.1
  enabled: true
  config:
  overrideConfig:
    filebeat.autodiscover:
      providers:
        - type: kubernetes
          hints.enabled: true
          include_annotations: '*'
          include_labels: '*'
          templates:
            - condition:
                or:
                - equals:
                    kubernetes.namespace: "linkerd"
                - equals:
                    kubernetes.namespace: "elasticsearch"
    output.file.enabled: false
    output.logstash:
      hosts: ["elasticsearch-logstash.elasticsearch.svc.cluster.local:5044"]
    indexTemplateLoad:
     - elasticsearch-client.elasticsearch:9200
    multiline:
      pattern: '^\['
      negate: true
      match: after
    filebeat.config:
      modules:
        path: ${path.config}/modules.d/*.yml
        # Reload module configs as they change:
        reload.enabled: false

    processors:
      - add_cloud_metadata: ~
      - add_kubernetes_metadata:
          in_cluster: true
    output.file:
      path: "/usr/share/filebeat/data"
      filename: filebeat
      rotate_every_kb: 10000
      number_of_files: 5

    # When a key contains a period, use this format for setting values on the command line:
    # --set config."http\.enabled"=true
    http.enabled: true
    http.port: 5066

fluentd:
  enabled: false

fluent-bit:
  enabled: false

fluentd-elasticsearch:
  enabled: false

nginx-ldapauth-proxy:
  enabled: false
  # Example config to get it working with ELK. Adjust as you need to.
  # proxy:
  #   port: 5601
  #   # This is the internal hostname for the kibana service
  #   host: "elk-kibana.default.svc.cluster.local"
  #   authName: "ELK:Infrastructure:LDAP"
  #   ldapHost: "ldap.example.com"
  #   ldapDN: "dc=example,dc=com"
  #   ldapFilter: "objectClass=organizationalPerson"
  #   ldapBindDN: "cn=reader,dc=example,dc=com"
  #   requires:
  #     - name: "ELK-USER"
  #       filter: "cn=elkuser,ou=groups,dc=example,dc=com"
  # ingress:
  #   enabled: true
  #   hosts:
  #     - "elk.example.com"
  #   annotations:
  #     kubernetes.io/ingress.class: nginx
  #   tls:
  #     - hosts:
  #       - elk.example.com
  #       secretName: example-elk-tls
  # secrets:
  #   ldapBindPassword: PASSWORD
elasticsearch-curator:
  enabled: false

elasticsearch-exporter:
  enabled: false
